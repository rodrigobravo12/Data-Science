import numpy as np
import pandas as pd
df = pd.read_csv('salaries.csv', sep = ',')

print(df.info())

print(df.head())

print(df.describe())

print(df.columns)

print(df.isnull().sum())

import seaborn as sns
import pandas as pd
df = pd.read_csv('salaries.csv', sep = ',')
sns.lineplot(data=df, x="work_year", y= "salary_in_usd").set_title("Evolución Salarios Data Science")

sns.barplot(x="remote_ratio", y="salary_in_usd", data=df)
sns.barplot(x="experience_level", y="salary_in_usd", data=df)

sns.displot(data=df, x= "experience_level", hue="remote_ratio", col="remote_ratio")

# Tomo como variable objetivo salary_in_usd y voy a intentar predecir el salario con un modelo de aprendizaje supervisado
# con regresión lineal

# Preprocesamiento

from sklearn.preprocessing import LabelEncoder

# Entrenamiento

from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score

# Algoritmos

from sklearn.linear_model import LinearRegression, Ridge, Lasso, RidgeCV
from sklearn.neighbors import KNeighborsRegressor as KNN
from xgboost import XGBRegressor

# Preprocesamiento Label Encoder para las variables categóricas

column = ['experience_level', 'employment_type', 'job_title', 'salary_currency', 'employee_residence', 'company_location', 'company_size']

df[column] = df[column].apply(LabelEncoder().fit_transform)

# Modelado

X = df.drop(['salary_in_usd'],axis=1)
y = df['salary_in_usd']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=16)

print('x_train size', X_train.shape)
print('y_train size', y_train.shape)
print('x_test size', X_test.shape)
print('y_test size', y_test.shape)

# Regresión Lineal (instanciamos el modelo)

model = LinearRegression()

# Entrenamiento

model.fit(X_train, y_train)

# Predicción

y_pred = model.predict(X_test)

# Medición

r2_rl = r2_score(y_test, y_pred)
r2_rl

# KNN (instanciamos el modelo)

model = KNN(n_neighbors=5, weights="uniform", metric="manhattan")

# Entrenamiento

model.fit(X_train, y_train)

# Predicción

y_pred = model.predict(X_test)

# Medición

r2_knn = r2_score(y_test, y_pred)
r2_knn

# XGBOOST (instanciamos el modelo)

model = XGBRegressor(n_estimators=2000 , max_depth= 7 , learning_rate = 0.01)

# Entrenamiento

model.fit(X_train, y_train)

# Predicción

y_pred = model.predict(X_test)

# Medición

r2_xgb = r2_score(y_test, y_pred)
r2_xgb

# El modelo más preciso es XGBOOST con el riesgo de overfitting
